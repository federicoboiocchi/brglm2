% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mdyplFit.R, R/zzz_conventions.R
\name{mdyplFit}
\alias{mdyplFit}
\alias{mdypl_fit}
\title{Fitting function for \code{\link[=glm]{glm()}} for maximum Diaconis-Ylvisaker prior
penalized likelihood estimation of logistic regression models}
\usage{
mdyplFit(
  x,
  y,
  weights = rep(1, nobs),
  start = NULL,
  etastart = NULL,
  mustart = NULL,
  offset = rep(0, nobs),
  family = binomial(),
  control = list(),
  intercept = TRUE,
  fixed_totals = NULL,
  singular.ok = TRUE
)

mdypl_fit(
  x,
  y,
  weights = rep(1, nobs),
  start = NULL,
  etastart = NULL,
  mustart = NULL,
  offset = rep(0, nobs),
  family = binomial(),
  control = list(),
  intercept = TRUE,
  fixed_totals = NULL,
  singular.ok = TRUE
)
}
\arguments{
\item{x}{a design matrix of dimension \code{n * p}.}

\item{y}{a vector of observations of length \code{n}.}

\item{weights}{an optional vector of \sQuote{prior weights} to be used
    in the fitting process.  Should be \code{NULL} or a numeric vector.}

\item{start}{starting values for the parameters in the linear predictor.}

\item{etastart}{starting values for the linear predictor.}

\item{mustart}{starting values for the vector of means.}

\item{offset}{this can be used to specify an \emph{a priori} known
    component to be included in the linear predictor during fitting.
    This should be \code{NULL} or a numeric vector of length equal to
    the number of cases.  One or more \code{\link[stats]{offset}} terms can be
    included in the formula instead or as well, and if more than one is
    specified their sum is used.  See \code{\link[stats]{model.offset}}.}

\item{family}{a description of the error distribution and link
    function to be used in the model.  For \code{glm} this can be a
    character string naming a family function, a family function or the
    result of a call to a family function.  For \code{glm.fit} only the
    third option is supported.  (See \code{\link[stats]{family}} for details of
    family functions.)}

\item{control}{a list of parameters controlling the fitting
process. See \code{\link[=mdyplControl]{mdyplControl()}} for details.}

\item{intercept}{logical. Should an intercept be included in the
    \emph{null} model?}

\item{singular.ok}{logical; if \code{FALSE} a singular fit is an
    error.}
}
\value{
An object inheriting from \code{\link[=mdyplFit]{"mdyplFit"}} object, which
is a list having the same elements to the list that
\code{\link[stats:glm]{stats::glm.fit()}} returns, with a few extra arguments. By default,
\code{alpha = m / (p + m)} is used, where \code{m} is the sum of the binomial
totals. Alternative values of \code{alpha} can be passed to the
\code{control} argument; see \code{\link[=mdyplControl]{mdyplControl()}} for setting up the list
passed to \code{control}.
}
\description{
\code{\link[=mdyplFit]{mdyplFit()}} is a fitting method for \code{\link[=glm]{glm()}} that fits logistic
regression models using maximum Diaconis-Ylvisaker prior penalized
likelihood estimation.
}
\details{
\code{\link[=mdyplFit]{mdyplFit()}} uses \code{\link[stats:glm]{stats::glm.fit()}} to fit a logistic regression
model on responses \code{alpha * y + (1 - alpha) / 2}, where \code{y} are the
orginal binomial responses scaled by the binomial totals. This is
equivalent to penalizing the likelihood by the Diaconis-Ylvisaker
prior with shirnkage parameter $\alpha$ and regression parameters
set to zero. See Rigon & Aliverti (2023) and Sterzinger & Kosmidis
(2024).

\code{\link[=mdypl_fit]{mdypl_fit()}} is an alias to \code{\link[=mdyplFit]{mdyplFit()}}.
}
\examples{

## A simulated data set as in Rigon & Aliverti (2023, Section 4.3)

set.seed(123)
n <- 1000
p <- 200
gamma <- 5
X <- matrix(rnorm(n * p, 0, 1), nrow = n, ncol = p)
betas0 <- rep(c(-1, -1/2, 0, 2, 3), each = p / 5)
betas <- gamma * betas0 / sqrt(sum(betas0^2))
probs <- plogis(drop(X \%*\% betas))
y <- rbinom(n, 1, probs)
fit_mdypl <- glm(y ~ -1 + X, family = binomial(), method = "mdyplFit")

## The default value of `alpha` is `n / (n + p)` here
identical(n / (n + p), fit_mdypl$alpha)

cols <- hcl.colors(3, alpha = 0.2)
par(mfrow = c(1, 2))
plot(betas, type = "l", ylim = c(-1, 1),
     main = "MDYPL estimates",
     xlab = "Parameter index", ylab = NA)
points(coef(fit_mdypl), col = NA, bg = cols[1], pch = 21)
sc_betas <- hd_summary.mdyplFit(fit_mdypl, se_start = c(0.5, 1, 1))
plot(betas, type = "l", ylim = c(-1, 1),
     main = "rescaled MDYPL estimates",
     xlab = "Parameter index", ylab = NA)
points(sc_betas[, "Rescaled-estimate"], col = NA, bg = cols[2], pch = 21)

}
\references{
Sterzinger P, Kosmidis I (2024). Diaconis-Ylvisaker prior
penalized likelihood for \eqn{p/n \to \kappa \in (0,1)} logistic
regression. \emph{arXiv}:2311.07419v2, \url{https://arxiv.org/abs/2311.07419}.

Rigon T, Aliverti E (2023). Conjugate priors and bias reduction for
logistic regression models. \emph{Statistics & Probability Letters},
\strong{202}, 109901. \doi{10.1016/j.spl.2023.109901}.
}
\seealso{
\code{\link[=mdyPLcontrol]{mdyPLcontrol()}}, \code{\link[=glm.fit]{glm.fit()}}, \code{\link[=glm]{glm()}}
}
\author{
Ioannis Kosmidis \verb{[aut, cre]} \email{ioannis.kosmidis@warwick.ac.uk}
}
